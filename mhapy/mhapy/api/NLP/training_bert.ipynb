{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict, Counter\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Train on gpu: True\n",
      "1 gpus detected.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda\" \n",
    "else: \n",
    "    dev = \"cpu\" \n",
    "device = torch.device(dev) \n",
    "print(device)\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')\n",
    "\n",
    "# Number of gpus\n",
    "if train_on_gpu:\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f'{gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/Mental Health Dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                posts predicted  intensity\n",
      "4   gmos now link to leukemia http nsnbc I 2013 07...   neutral          0\n",
      "5   here is a link for an interesting article and ...   neutral          0\n",
      "8   the third know human retrovirus xmrv seem to b...   neutral          0\n",
      "9   leukemia survivor meet his bone marrow donor w...   neutral          0\n",
      "10  melt down can not stop the water work today I ...   neutral          0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "long_posts_df = df[df['posts'].str.split().str.len() > 300]\n",
    "\n",
    "#eject all posts with more than 300 words\n",
    "short_posts_df = df[df['posts'].str.split().str.len() <= 300]\n",
    "print(short_posts_df.head())\n",
    "print(short_posts_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = short_posts_df.drop('intensity', axis=1)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized = tokenizer.batch_encode_plus(\n",
    "    new_df['posts'].tolist(),\n",
    "    add_special_tokens=False,\n",
    "    max_length=250,\n",
    "    padding='longest',\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    return_attention_mask=False,\n",
    "    return_token_type_ids=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8104, 391])\n",
      "torch.Size([8104])\n",
      "tensor([2, 2, 2,  ..., 0, 2, 1], device='cuda:0')\n",
      "Class 2: 3432 occurrences\n",
      "Class 1: 3189 occurrences\n",
      "Class 0: 914 occurrences\n",
      "Class 3: 569 occurrences\n"
     ]
    }
   ],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "tokenized['intensity'] = le.fit_transform(short_posts_df['intensity'])\n",
    "\n",
    "tokenized['intensity'] = torch.tensor(tokenized['intensity'])\n",
    "\n",
    "\n",
    "tokenized['input_ids'] = tokenized['input_ids'].to(device)\n",
    "tokenized['intensity'] = tokenized['intensity'].to(device)\n",
    "print(tokenized['input_ids'].shape) \n",
    "print(tokenized['intensity'].shape)\n",
    "\n",
    "print(tokenized['intensity'])\n",
    "counter = Counter(tokenized['intensity'].tolist())\n",
    "for label, count in counter.items():\n",
    "    print(f\"Class {label}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5672 1216 1216\n"
     ]
    }
   ],
   "source": [
    "total_dataset = TensorDataset(tokenized['input_ids'], tokenized['intensity'])\n",
    "train_size = int(0.7 * len(total_dataset))\n",
    "val_size = len(total_dataset) - train_size\n",
    "test_size = int(0.5 * val_size)\n",
    "val_size = val_size - test_size\n",
    "print(train_size, val_size, test_size)\n",
    "train_dataset, val_dataset, test_dataset = random_split(total_dataset, [train_size, val_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
      ")\n",
      "cuda:0\n",
      "<class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "                                      'bert-base-uncased', \n",
    "                                      num_labels = 4,\n",
    "                                      output_attentions = False,\n",
    "                                      output_hidden_states = False\n",
    "                                     )\n",
    "\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Linear(in_features=768, out_features=4, bias=True)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "print(model.device)\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpameters = {'batch_size': 60, 'learning_rate': 0.001, 'epochs': 2, 'optimizer': 'Adam'} \n",
    "adam = torch.optim.Adam(model.parameters(), lr=hyperpameters['learning_rate'])\n",
    "hyperpameters['optimizer'] = adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = hyperpameters['batch_size'],  \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=hyperpameters['batch_size'],  \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=hyperpameters['batch_size'],  \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, test_dataloader, epochs, optimizer, criterion, train_on_gpu, save_path, save=False):\n",
    "    history = []\n",
    "    valid_loss_min = np.Inf\n",
    "    overall_start = timer()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = timer()\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        valid_acc = 0\n",
    "        train_acc = 0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for index, (data, target) in enumerate(train_dataloader):\n",
    "            \n",
    "            if train_on_gpu:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            print(data.device)\n",
    "            print(model.device)\n",
    "            print(data.shape)\n",
    "            output = model(data).logits\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "\n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "            \n",
    "            print(f'Epoch: {epoch}\\t{100 * (index + 1) / len(train_dataloader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.', end='\\r')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for data, target in val_dataloader:\n",
    "                    # Tensors to gpu\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    \n",
    "                output = model(data).logits\n",
    "\n",
    "                    \n",
    "                loss = criterion(output, target)\n",
    "                    \n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                _, pred = torch.max(output, dim=1)\n",
    "                correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "                    \n",
    "            valid_acc += accuracy.item() * data.size(0)\n",
    "            train_loss = train_loss / len(train_dataloader.dataset)\n",
    "            valid_loss = valid_loss / len(val_dataloader.dataset)\n",
    "\n",
    "            # Calculate average accuracy\n",
    "            train_acc = train_acc / len(train_dataloader.dataset)\n",
    "            valid_acc = valid_acc / len(val_dataloader.dataset)\n",
    "            history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "            \n",
    "            print(f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}')\n",
    "            print(f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%')\n",
    "    model.optimizer = optimizer\n",
    "    total_time = timer() - overall_start\n",
    "    print(f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.')\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t1.05% complete. 1.22 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t2.11% complete. 2.36 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t3.16% complete. 3.49 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t4.21% complete. 4.63 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t5.26% complete. 5.76 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t6.32% complete. 6.89 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t7.37% complete. 8.02 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t8.42% complete. 9.15 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t9.47% complete. 10.28 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t10.53% complete. 11.42 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t11.58% complete. 12.58 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t12.63% complete. 13.75 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t13.68% complete. 14.90 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t14.74% complete. 16.03 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t15.79% complete. 17.16 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t16.84% complete. 18.29 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t17.89% complete. 19.43 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t18.95% complete. 20.56 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t20.00% complete. 21.69 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t21.05% complete. 22.82 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t22.11% complete. 23.96 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t23.16% complete. 25.11 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t24.21% complete. 26.26 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t25.26% complete. 27.43 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t26.32% complete. 28.58 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t27.37% complete. 29.74 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t28.42% complete. 30.89 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t29.47% complete. 32.04 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t30.53% complete. 33.19 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t31.58% complete. 34.35 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t32.63% complete. 35.49 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t33.68% complete. 36.63 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t34.74% complete. 37.80 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t35.79% complete. 38.90 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t36.84% complete. 40.00 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t37.89% complete. 41.10 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t38.95% complete. 42.20 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t40.00% complete. 43.30 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t41.05% complete. 44.41 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t42.11% complete. 45.56 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t43.16% complete. 46.72 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t44.21% complete. 47.87 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t45.26% complete. 49.03 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t46.32% complete. 50.19 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t47.37% complete. 51.34 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t48.42% complete. 52.50 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t49.47% complete. 53.65 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t50.53% complete. 54.80 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t51.58% complete. 55.95 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t52.63% complete. 57.10 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t53.68% complete. 58.26 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t54.74% complete. 59.41 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t55.79% complete. 60.56 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t56.84% complete. 61.72 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t57.89% complete. 62.86 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t58.95% complete. 64.02 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t60.00% complete. 65.13 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t61.05% complete. 66.24 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t62.11% complete. 67.33 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t63.16% complete. 68.47 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t64.21% complete. 69.66 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t65.26% complete. 70.82 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t66.32% complete. 71.99 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t67.37% complete. 73.16 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t68.42% complete. 74.32 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t69.47% complete. 75.49 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t70.53% complete. 76.66 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t71.58% complete. 77.83 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t72.63% complete. 78.99 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t73.68% complete. 80.17 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t74.74% complete. 81.34 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t75.79% complete. 82.49 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t76.84% complete. 83.64 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t77.89% complete. 84.79 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t78.95% complete. 85.93 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t80.00% complete. 87.07 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t81.05% complete. 88.21 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t82.11% complete. 89.36 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t83.16% complete. 90.53 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t84.21% complete. 91.68 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t85.26% complete. 92.85 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t86.32% complete. 94.01 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t87.37% complete. 95.16 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t88.42% complete. 96.31 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t89.47% complete. 97.46 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t90.53% complete. 98.61 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t91.58% complete. 99.76 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t92.63% complete. 100.92 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t93.68% complete. 102.07 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t94.74% complete. 103.22 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t95.79% complete. 104.38 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t96.84% complete. 105.53 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t97.89% complete. 106.65 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 0\t98.95% complete. 107.78 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([32, 391])\n",
      "Epoch: 0\t100.00% complete. 108.40 seconds elapsed in epoch.\n",
      "Epoch: 0 \tTraining Loss: 1.3111 \tValidation Loss: 1.3182\n",
      "\t\tTraining Accuracy: 35.53%\t Validation Accuracy: 0.49%\n",
      "cuda:0\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t1.05% complete. 1.15 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t2.11% complete. 2.30 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t3.16% complete. 3.42 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t4.21% complete. 4.54 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t5.26% complete. 5.66 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t6.32% complete. 6.77 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t7.37% complete. 7.89 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t8.42% complete. 9.02 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t9.47% complete. 10.14 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t10.53% complete. 11.32 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t11.58% complete. 12.47 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t12.63% complete. 13.59 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t13.68% complete. 14.75 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t14.74% complete. 15.87 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t15.79% complete. 16.99 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t16.84% complete. 18.11 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t17.89% complete. 19.24 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t18.95% complete. 20.36 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t20.00% complete. 21.49 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t21.05% complete. 22.61 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t22.11% complete. 23.73 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t23.16% complete. 24.86 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t24.21% complete. 25.98 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t25.26% complete. 27.15 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t26.32% complete. 28.28 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t27.37% complete. 29.42 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t28.42% complete. 30.55 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t29.47% complete. 31.70 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t30.53% complete. 32.86 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t31.58% complete. 34.02 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t32.63% complete. 35.15 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t33.68% complete. 36.28 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t34.74% complete. 37.40 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t35.79% complete. 38.53 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t36.84% complete. 39.65 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t37.89% complete. 40.86 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t38.95% complete. 41.98 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t40.00% complete. 43.11 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t41.05% complete. 44.25 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t42.11% complete. 45.37 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t43.16% complete. 46.50 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t44.21% complete. 47.63 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t45.26% complete. 48.76 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t46.32% complete. 49.93 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t47.37% complete. 51.09 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t48.42% complete. 52.22 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t49.47% complete. 53.42 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t50.53% complete. 54.55 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t51.58% complete. 55.67 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t52.63% complete. 56.86 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t53.68% complete. 57.98 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t54.74% complete. 59.14 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t55.79% complete. 60.27 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t56.84% complete. 61.39 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t57.89% complete. 62.53 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t58.95% complete. 63.68 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t60.00% complete. 64.80 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t61.05% complete. 65.96 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t62.11% complete. 67.08 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t63.16% complete. 68.23 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t64.21% complete. 69.43 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t65.26% complete. 70.56 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t66.32% complete. 71.69 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t67.37% complete. 72.82 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t68.42% complete. 73.95 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t69.47% complete. 75.07 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t70.53% complete. 76.24 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t71.58% complete. 77.37 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t72.63% complete. 78.50 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t73.68% complete. 79.69 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t74.74% complete. 80.81 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t75.79% complete. 81.94 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t76.84% complete. 83.07 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t77.89% complete. 84.22 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t78.95% complete. 85.35 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t80.00% complete. 86.53 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t81.05% complete. 87.65 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t82.11% complete. 88.80 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t83.16% complete. 90.07 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t84.21% complete. 91.65 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t85.26% complete. 92.84 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t86.32% complete. 94.02 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t87.37% complete. 95.16 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t88.42% complete. 96.28 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t89.47% complete. 97.41 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t90.53% complete. 98.53 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t91.58% complete. 99.65 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t92.63% complete. 100.78 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t93.68% complete. 101.91 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t94.74% complete. 103.05 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t95.79% complete. 104.18 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t96.84% complete. 105.31 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t97.89% complete. 106.45 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([60, 391])\n",
      "cuda:0 1\t98.95% complete. 107.57 seconds elapsed in epoch.\n",
      "cuda:0\n",
      "torch.Size([32, 391])\n",
      "Epoch: 1\t100.00% complete. 108.19 seconds elapsed in epoch.\n",
      "Epoch: 1 \tTraining Loss: 1.3113 \tValidation Loss: 1.3182\n",
      "\t\tTraining Accuracy: 35.72%\t Validation Accuracy: 0.41%\n",
      "262.02 total seconds elapsed. 262.02 seconds per epoch.\n"
     ]
    }
   ],
   "source": [
    "model, history = train(model, train_dataloader, val_dataloader, test_dataloader, hyperpameters['epochs'], hyperpameters['optimizer'], criterion, train_on_gpu, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.classifier.state_dict(), 'Models/BERT_last_layer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
